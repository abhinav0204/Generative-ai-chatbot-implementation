{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "262ee4c7-9438-4f24-8f0b-1c23e16078ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: spacy in /databricks/python3/lib/python3.10/site-packages (3.7.2)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /databricks/python3/lib/python3.10/site-packages (from spacy) (8.2.2)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from spacy) (65.6.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.10.6)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (2.28.1)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: numpy>=1.19.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.23.5)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /databricks/python3/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /databricks/python3/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (4.64.1)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /databricks/python3/lib/python3.10/site-packages (from spacy) (5.2.1)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /databricks/python3/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from spacy) (23.2)\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /databricks/python3/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting textblob\n  Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 626.3/626.3 kB 6.8 MB/s eta 0:00:00\nCollecting nltk>=3.8\n  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 12.5 MB/s eta 0:00:00\nRequirement already satisfied: click in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (8.0.4)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (4.64.1)\nRequirement already satisfied: regex>=2021.8.3 in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (2022.7.9)\nRequirement already satisfied: joblib in /databricks/python3/lib/python3.10/site-packages (from nltk>=3.8->textblob) (1.2.0)\nInstalling collected packages: nltk, textblob\n  Attempting uninstall: nltk\n    Found existing installation: nltk 3.7\n    Not uninstalling nltk at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740\n    Can't uninstall 'nltk'. No files were found to uninstall.\nSuccessfully installed nltk-3.9.1 textblob-0.18.0.post0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting googletrans\n  Downloading googletrans-3.0.0.tar.gz (17 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting httpx==0.13.3\n  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.1/55.1 kB 2.7 MB/s eta 0:00:00\nCollecting chardet==3.*\n  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.4/133.4 kB 5.3 MB/s eta 0:00:00\nRequirement already satisfied: certifi in /databricks/python3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (2022.12.7)\nRequirement already satisfied: sniffio in /databricks/python3/lib/python3.10/site-packages (from httpx==0.13.3->googletrans) (1.2.0)\nCollecting idna==2.*\n  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 5.5 MB/s eta 0:00:00\nCollecting rfc3986<2,>=1.3\n  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\nCollecting hstspreload\n  Downloading hstspreload-2024.12.1-py3-none-any.whl (1.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 10.7 MB/s eta 0:00:00\nCollecting httpcore==0.9.*\n  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 6.4 MB/s eta 0:00:00\nCollecting h11<0.10,>=0.8\n  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.6/53.6 kB 7.5 MB/s eta 0:00:00\nCollecting h2==3.*\n  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.0/65.0 kB 7.2 MB/s eta 0:00:00\nCollecting hyperframe<6,>=5.2.0\n  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\nCollecting hpack<4,>=3.0\n  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\nBuilding wheels for collected packages: googletrans\n  Building wheel for googletrans (setup.py): started\n  Building wheel for googletrans (setup.py): finished with status 'done'\n  Created wheel for googletrans: filename=googletrans-3.0.0-py3-none-any.whl size=15719 sha256=8082de23116b95858713cfc2e3ce51f7af261c15f3fed497556f2b241c32e033\n  Stored in directory: /root/.cache/pip/wheels/cd/ca/87/9a9849f1ceedf19652e3fc8a5bf2bd5b2e151b7b158c79bf5b\nSuccessfully built googletrans\nInstalling collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n  Attempting uninstall: chardet\n    Found existing installation: chardet 4.0.0\n    Not uninstalling chardet at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740\n    Can't uninstall 'chardet'. No files were found to uninstall.\n  Attempting uninstall: idna\n    Found existing installation: idna 3.4\n    Not uninstalling idna at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740\n    Can't uninstall 'idna'. No files were found to uninstall.\nERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatabricks-feature-engineering 0.2.1 requires pyspark<4,>=3.1.2, which is not installed.\nSuccessfully installed chardet-3.0.4 googletrans-3.0.0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.12.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nRequirement already satisfied: openai in /databricks/python3/lib/python3.10/site-packages (0.28.1)\nRequirement already satisfied: aiohttp in /databricks/python3/lib/python3.10/site-packages (from openai) (3.9.1)\nRequirement already satisfied: requests>=2.20 in /databricks/python3/lib/python3.10/site-packages (from openai) (2.28.1)\nRequirement already satisfied: tqdm in /databricks/python3/lib/python3.10/site-packages (from openai) (4.64.1)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.20->openai) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.20->openai) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740/lib/python3.10/site-packages (from requests>=2.20->openai) (2.10)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests>=2.20->openai) (2.0.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.3.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (22.1.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /databricks/python3/lib/python3.10/site-packages (from aiohttp->openai) (1.4.1)\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!pip install textblob\n",
    "!pip install googletrans\n",
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cd10180-9daf-49ae-9405-f49465859efb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\nCollecting diffusers\n  Downloading diffusers-0.31.0-py3-none-any.whl (2.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 10.8 MB/s eta 0:00:00\nRequirement already satisfied: transformers in /databricks/python3/lib/python3.10/site-packages (4.36.1)\nRequirement already satisfied: torch in /databricks/python3/lib/python3.10/site-packages (2.0.1+cpu)\nRequirement already satisfied: filelock in /databricks/python3/lib/python3.10/site-packages (from diffusers) (3.9.0)\nRequirement already satisfied: numpy in /databricks/python3/lib/python3.10/site-packages (from diffusers) (1.23.5)\nRequirement already satisfied: Pillow in /databricks/python3/lib/python3.10/site-packages (from diffusers) (9.4.0)\nRequirement already satisfied: requests in /databricks/python3/lib/python3.10/site-packages (from diffusers) (2.28.1)\nRequirement already satisfied: regex!=2019.12.17 in /databricks/python3/lib/python3.10/site-packages (from diffusers) (2022.7.9)\nCollecting huggingface-hub>=0.23.2\n  Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 447.8/447.8 kB 16.4 MB/s eta 0:00:00\nRequirement already satisfied: safetensors>=0.3.1 in /databricks/python3/lib/python3.10/site-packages (from diffusers) (0.4.1)\nRequirement already satisfied: importlib-metadata in /databricks/python3/lib/python3.10/site-packages (from diffusers) (4.11.3)\nRequirement already satisfied: pyyaml>=5.1 in /databricks/python3/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /databricks/python3/lib/python3.10/site-packages (from transformers) (0.15.0)\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from transformers) (23.2)\nRequirement already satisfied: tqdm>=4.27 in /databricks/python3/lib/python3.10/site-packages (from transformers) (4.64.1)\nRequirement already satisfied: typing-extensions in /databricks/python3/lib/python3.10/site-packages (from torch) (4.4.0)\nRequirement already satisfied: sympy in /databricks/python3/lib/python3.10/site-packages (from torch) (1.11.1)\nRequirement already satisfied: networkx in /databricks/python3/lib/python3.10/site-packages (from torch) (2.8.4)\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /databricks/python3/lib/python3.10/site-packages (from huggingface-hub>=0.23.2->diffusers) (2023.6.0)\nRequirement already satisfied: zipp>=0.5 in /databricks/python3/lib/python3.10/site-packages (from importlib-metadata->diffusers) (3.11.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740/lib/python3.10/site-packages (from requests->diffusers) (2.10)\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests->diffusers) (2.0.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests->diffusers) (1.26.14)\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests->diffusers) (2022.12.7)\nRequirement already satisfied: mpmath>=0.19 in /databricks/python3/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\nInstalling collected packages: huggingface-hub, diffusers\n  Attempting uninstall: huggingface-hub\n    Found existing installation: huggingface-hub 0.19.4\n    Not uninstalling huggingface-hub at /databricks/python3/lib/python3.10/site-packages, outside environment /local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740\n    Can't uninstall 'huggingface-hub'. No files were found to uninstall.\nSuccessfully installed diffusers-0.31.0 huggingface-hub-0.26.5\n\u001B[43mNote: you may need to restart the kernel using dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install diffusers transformers torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "63b9044b-b884-48c3-9a33-b8398c6facde",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\r\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\r\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/12.8 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.1/12.8 MB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:04\u001B[0m\r\u001B[2K     \u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.2/12.8 MB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:04\u001B[0m\r\u001B[2K     \u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.2/12.8 MB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:06\u001B[0m\r\u001B[2K     \u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.3/12.8 MB\u001B[0m \u001B[31m2.4 MB/s\u001B[0m eta \u001B[36m0:00:06\u001B[0m\r\u001B[2K     \u001B[91m━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.4/12.8 MB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:05\u001B[0m\r\u001B[2K     \u001B[91m━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.6/12.8 MB\u001B[0m \u001B[31m3.1 MB/s\u001B[0m eta \u001B[36m0:00:04\u001B[0m\r\u001B[2K     \u001B[91m━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.1/12.8 MB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:03\u001B[0m\r\u001B[2K     \u001B[91m━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.7/12.8 MB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.5/12.8 MB\u001B[0m \u001B[31m7.9 MB/s\u001B[0m eta \u001B[36m0:00:02\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.3/12.8 MB\u001B[0m \u001B[31m9.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m4.4/12.8 MB\u001B[0m \u001B[31m11.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.7/12.8 MB\u001B[0m \u001B[31m13.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.1/12.8 MB\u001B[0m \u001B[31m15.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[90m╺\u001B[0m\u001B[90m━━━━━━━━━━━\u001B[0m \u001B[32m9.0/12.8 MB\u001B[0m \u001B[31m18.6 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m\u001B[90m━━━━━\u001B[0m \u001B[32m11.2/12.8 MB\u001B[0m \u001B[31m35.3 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m44.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[91m╸\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m44.9 MB/s\u001B[0m eta \u001B[36m0:00:01\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.8/12.8 MB\u001B[0m \u001B[31m36.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /databricks/python3/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\r\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.28.1)\r\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\r\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\r\nRequirement already satisfied: setuptools in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.6.3)\r\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.64.1)\r\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\r\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\r\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\r\nRequirement already satisfied: jinja2 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\r\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\r\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.6)\r\nRequirement already satisfied: packaging>=20.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\r\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\r\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\r\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\r\nRequirement already satisfied: numpy>=1.19.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.5)\r\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\r\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\r\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\r\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /databricks/python3/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\r\nRequirement already satisfied: typing-extensions>=4.2.0 in /databricks/python3/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.4.0)\r\nRequirement already satisfied: idna<4,>=2.5 in /local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.10)\r\nRequirement already satisfied: certifi>=2017.4.17 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.12.7)\r\nRequirement already satisfied: charset-normalizer<3,>=2 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\r\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /databricks/python3/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.14)\r\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\r\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /databricks/python3/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\r\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /databricks/python3/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\r\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /databricks/python3/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\r\nRequirement already satisfied: MarkupSafe>=2.0 in /databricks/python3/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\r\nInstalling collected packages: en-core-web-sm\r\nSuccessfully installed en-core-web-sm-3.7.1\r\n\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m A new release of pip available: \u001B[0m\u001B[31;49m22.3.1\u001B[0m\u001B[39;49m -> \u001B[0m\u001B[32;49m24.3.1\u001B[0m\r\n\u001B[1m[\u001B[0m\u001B[34;49mnotice\u001B[0m\u001B[1;39;49m]\u001B[0m\u001B[39;49m To update, run: \u001B[0m\u001B[32;49mpip install --upgrade pip\u001B[0m\r\n\u001B[38;5;2m✔ Download and installation successful\u001B[0m\r\nYou can now load the package via spacy.load('en_core_web_sm')\r\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e53d70c-991c-4a7f-a28e-95129aaa0ecd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "96d768cc-0b4e-4f13-b1cd-8fe95cad4f57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is running. Type 'exit' to quit.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  sunset"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\nNo named entities found.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  lion"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\nNamed Entities:\n  - lion (ORG)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  donald trump"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\nNamed Entities:\n  - donald trump (PERSON)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from googletrans import Translator\n",
    "from transformers import pipeline\n",
    "\n",
    "# Load spaCy model for named entity recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "translator = Translator()\n",
    "\n",
    "# Load Hugging Face image classification pipeline\n",
    "image_pipeline = pipeline(\"image-classification\")\n",
    "\n",
    "def classify_sentiment(prompt):\n",
    "    \"\"\"Classify sentiment as Positive or Negative.\"\"\"\n",
    "    analysis = TextBlob(prompt)\n",
    "    sentiment = \"Positive\" if analysis.sentiment.polarity > 0 else \"Negative\"\n",
    "    return sentiment\n",
    "\n",
    "def extract_named_entities(prompt):\n",
    "    \"\"\"Extract named entities from the prompt.\"\"\"\n",
    "    doc = nlp(prompt)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "def identify_request_type(prompt):\n",
    "    \"\"\"Identify if the request is for text, image, or translation.\"\"\"\n",
    "    prompt_lower = prompt.lower()\n",
    "    if \"image\" in prompt_lower or \"picture\" in prompt_lower:\n",
    "        return \"image\"\n",
    "    elif \"translate\" in prompt_lower:\n",
    "        return \"translation\"\n",
    "    else:\n",
    "        return \"text\"\n",
    "\n",
    "def generate_image_and_captions(prompt):\n",
    "    \"\"\"Generate an image and captions based on the input prompt.\"\"\"\n",
    "    try:\n",
    "        # Generate image using Hugging Face image-classification pipeline\n",
    "        outputs = image_pipeline(prompt, num_images=1)\n",
    "        image_url = outputs[0]['img'] if 'img' in outputs[0] else None\n",
    "\n",
    "        # Generate captions for the image\n",
    "        captions = [\n",
    "            f\"Generated image based on the prompt: {prompt}\",\n",
    "            \"This image was created using AI based on your request.\",\n",
    "            \"An artistic interpretation of the described scene.\"\n",
    "        ]\n",
    "\n",
    "        return image_url, captions\n",
    "    except Exception as e:\n",
    "        return None, [f\"Error generating image: {e}\"]\n",
    "\n",
    "def translate_to_french(text):\n",
    "    \"\"\"Translate the given text to French.\"\"\"\n",
    "    translation = translator.translate(text, src=\"en\", dest=\"fr\") if text else None\n",
    "    return translation.text if translation else None\n",
    "\n",
    "def chatbot():\n",
    "    \"\"\"Chatbot loop that processes input and performs tasks.\"\"\"\n",
    "    print(\"Chatbot is running. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Identify request type\n",
    "        request_type = identify_request_type(user_input)\n",
    "\n",
    "        if request_type == \"image\":\n",
    "            # Generate image and captions\n",
    "            image_url, captions = generate_image_and_captions(user_input)\n",
    "            if image_url:\n",
    "                print(f\"Image URL: {image_url}\")\n",
    "                print(\"Captions:\")\n",
    "                for caption in captions:\n",
    "                    print(f\"  - {caption}\")\n",
    "            else:\n",
    "                print(\"Failed to generate image.\")\n",
    "\n",
    "        elif request_type == \"translation\":\n",
    "            # Translate to French\n",
    "            translation = translate_to_french(user_input)\n",
    "            print(f\"Translation to French: {translation}\")\n",
    "        \n",
    "        else:\n",
    "            # Classify sentiment\n",
    "            sentiment = classify_sentiment(user_input)\n",
    "            print(f\"Sentiment: {sentiment}\")\n",
    "\n",
    "            # Extract named entities\n",
    "            entities = extract_named_entities(user_input)\n",
    "            if entities:\n",
    "                print(\"Named Entities:\")\n",
    "                for entity, label in entities:\n",
    "                    print(f\"  - {entity} ({label})\")\n",
    "            else:\n",
    "                print(\"No named entities found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "902668cc-568e-4ae9-8b95-f7bdb4f17c93",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n/databricks/python/lib/python3.10/site-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, comment allez-vous?\n"
     ]
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "\n",
    "def translate_to_french_with_hf(text):\n",
    "    \"\"\"Translate text to French using Hugging Face.\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "# Example usage\n",
    "print(translate_to_french_with_hf(\"Hello, how are you?\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4d67b98f-815d-46c4-9ef2-5c566c9607c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to google/vit-base-patch16-224 and revision 5dca96d (https://huggingface.co/google/vit-base-patch16-224).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n/local_disk0/.ephemeral_nfs/envs/pythonEnv-26eb9fa3-d28c-4512-8713-31c4a0532740/lib/python3.10/site-packages/huggingface_hub/file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n  warnings.warn(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chatbot is running. Type 'exit' to quit.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  my name is tony stark"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\nNo named entities found.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  giraffe"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\nNo named entities found.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  exit"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment: Negative\nNo named entities found.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "You:  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "com.databricks.backend.common.rpc.CommandCancelledException\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)\n",
       "\tat scala.collection.immutable.Range.foreach(Range.scala:158)\n",
       "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:730)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:448)\n",
       "\tat scala.Option.getOrElse(Option.scala:189)\n",
       "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:448)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1311)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1028)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)\n",
       "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:989)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:799)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:825)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:824)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:879)\n",
       "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:672)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)\n",
       "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)\n",
       "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)\n",
       "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)\n",
       "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)\n",
       "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)\n",
       "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)\n",
       "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)\n",
       "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)\n",
       "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)\n",
       "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)\n",
       "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)\n",
       "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)\n",
       "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)\n",
       "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)\n",
       "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)\n",
       "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)\n",
       "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)\n",
       "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)\n",
       "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)\n",
       "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)\n",
       "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)\n",
       "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)\n",
       "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)\n",
       "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)\n",
       "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)\n",
       "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)\n",
       "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)\n",
       "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)\n",
       "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)\n",
       "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)\n",
       "\tat java.lang.Thread.run(Thread.java:750)"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "arguments": {},
       "datasetInfos": [],
       "jupyterProps": null,
       "metadata": {
        "errorSummary": "Cancelled"
       },
       "removedWidgets": [],
       "sqlProps": null,
       "stackFrames": [
        "com.databricks.backend.common.rpc.CommandCancelledException",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$5(SequenceExecutionState.scala:136)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3(SequenceExecutionState.scala:136)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.$anonfun$cancel$3$adapted(SequenceExecutionState.scala:133)",
        "\tat scala.collection.immutable.Range.foreach(Range.scala:158)",
        "\tat com.databricks.spark.chauffeur.SequenceExecutionState.cancel(SequenceExecutionState.scala:133)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancelRunningSequence(ExecContextState.scala:730)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.$anonfun$cancel$1(ExecContextState.scala:448)",
        "\tat scala.Option.getOrElse(Option.scala:189)",
        "\tat com.databricks.spark.chauffeur.ExecContextState.cancel(ExecContextState.scala:448)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.cancelExecution(ChauffeurState.scala:1311)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.$anonfun$process$1(ChauffeurState.scala:1028)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionContext(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.withAttributionTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperationWithResultTags(ChauffeurState.scala:74)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.recordOperation(ChauffeurState.scala:74)",
        "\tat com.databricks.spark.chauffeur.ChauffeurState.process(ChauffeurState.scala:989)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequest$1(Chauffeur.scala:799)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.$anonfun$applyOrElse$5(Chauffeur.scala:825)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.handleDriverRequestWithUsageLogging$1(Chauffeur.scala:824)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:879)",
        "\tat com.databricks.spark.chauffeur.Chauffeur$$anon$1$$anonfun$receive$1.applyOrElse(Chauffeur.scala:672)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive0$2(ServerBackend.scala:174)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend$$anonfun$commonReceive$1.applyOrElse(ServerBackend.scala:200)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive0(ServerBackend.scala:171)",
        "\tat com.databricks.rpc.ServerBackend.$anonfun$internalReceive$1(ServerBackend.scala:147)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperation$1(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.executeThunkAndCaptureResultTags$1(UsageLogging.scala:669)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$recordOperationWithResultTags$4(UsageLogging.scala:687)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionContext(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags(UsageLogging.scala:472)",
        "\tat com.databricks.logging.UsageLogging.withAttributionTags$(UsageLogging.scala:455)",
        "\tat com.databricks.rpc.ServerBackend.withAttributionTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags(UsageLogging.scala:664)",
        "\tat com.databricks.logging.UsageLogging.recordOperationWithResultTags$(UsageLogging.scala:582)",
        "\tat com.databricks.rpc.ServerBackend.recordOperationWithResultTags(ServerBackend.scala:22)",
        "\tat com.databricks.logging.UsageLogging.recordOperation(UsageLogging.scala:573)",
        "\tat com.databricks.logging.UsageLogging.recordOperation$(UsageLogging.scala:542)",
        "\tat com.databricks.rpc.ServerBackend.recordOperation(ServerBackend.scala:22)",
        "\tat com.databricks.rpc.ServerBackend.internalReceive(ServerBackend.scala:147)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRPC(JettyServer.scala:1020)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleRequestAndRespond(JettyServer.scala:941)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6(JettyServer.scala:545)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.$anonfun$handleHttp$6$adapted(JettyServer.scala:514)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$4(ActivityContextFactory.scala:405)",
        "\tat com.databricks.logging.UsageLogging.$anonfun$withAttributionContext$1(UsageLogging.scala:426)",
        "\tat scala.util.DynamicVariable.withValue(DynamicVariable.scala:62)",
        "\tat com.databricks.logging.AttributionContext$.withValue(AttributionContext.scala:216)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:424)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withAttributionContext(ActivityContextFactory.scala:58)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.$anonfun$withActivityInternal$1(ActivityContextFactory.scala:405)",
        "\tat com.databricks.context.integrity.IntegrityCheckContext$ThreadLocalStorage$.withValue(IntegrityCheckContext.scala:44)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withActivityInternal(ActivityContextFactory.scala:380)",
        "\tat com.databricks.logging.activity.ActivityContextFactory$.withServiceRequestActivity(ActivityContextFactory.scala:159)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.handleHttp(JettyServer.scala:514)",
        "\tat com.databricks.rpc.JettyServer$RequestManager.doPost(JettyServer.scala:404)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:665)",
        "\tat com.databricks.rpc.HttpServletWithPatch.service(HttpServletWithPatch.scala:33)",
        "\tat javax.servlet.http.HttpServlet.service(HttpServlet.java:750)",
        "\tat org.eclipse.jetty.servlet.ServletHolder.handle(ServletHolder.java:799)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doHandle(ServletHandler.java:554)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.nextScope(ScopedHandler.java:190)",
        "\tat org.eclipse.jetty.servlet.ServletHandler.doScope(ServletHandler.java:505)",
        "\tat org.eclipse.jetty.server.handler.ScopedHandler.handle(ScopedHandler.java:141)",
        "\tat org.eclipse.jetty.server.handler.HandlerWrapper.handle(HandlerWrapper.java:127)",
        "\tat org.eclipse.jetty.server.Server.handle(Server.java:516)",
        "\tat org.eclipse.jetty.server.HttpChannel.lambda$handle$1(HttpChannel.java:487)",
        "\tat org.eclipse.jetty.server.HttpChannel.dispatch(HttpChannel.java:732)",
        "\tat org.eclipse.jetty.server.HttpChannel.handle(HttpChannel.java:479)",
        "\tat org.eclipse.jetty.server.HttpConnection.onFillable(HttpConnection.java:277)",
        "\tat org.eclipse.jetty.io.AbstractConnection$ReadCallback.succeeded(AbstractConnection.java:311)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$DecryptedEndPoint.onFillable(SslConnection.java:555)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection.onFillable(SslConnection.java:410)",
        "\tat org.eclipse.jetty.io.ssl.SslConnection$2.succeeded(SslConnection.java:164)",
        "\tat org.eclipse.jetty.io.FillInterest.fillable(FillInterest.java:105)",
        "\tat org.eclipse.jetty.io.ChannelEndPoint$1.run(ChannelEndPoint.java:104)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.runTask(EatWhatYouKill.java:338)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.doProduce(EatWhatYouKill.java:315)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.tryProduce(EatWhatYouKill.java:173)",
        "\tat org.eclipse.jetty.util.thread.strategy.EatWhatYouKill.run(EatWhatYouKill.java:131)",
        "\tat org.eclipse.jetty.util.thread.ReservedThreadExecutor$ReservedThread.run(ReservedThreadExecutor.java:409)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$4(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext(UsageLogging.scala:420)",
        "\tat com.databricks.logging.UsageLogging.withAttributionContext$(UsageLogging.scala:418)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.withAttributionContext(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.$anonfun$run$1(InstrumentedQueuedThreadPool.scala:104)",
        "\tat scala.runtime.java8.JFunction0$mcV$sp.apply(JFunction0$mcV$sp.java:23)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads(QueuedThreadPoolInstrumenter.scala:66)",
        "\tat com.databricks.instrumentation.QueuedThreadPoolInstrumenter.trackActiveThreads$(QueuedThreadPoolInstrumenter.scala:63)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool.trackActiveThreads(InstrumentedQueuedThreadPool.scala:47)",
        "\tat com.databricks.rpc.InstrumentedQueuedThreadPool$$anon$1.run(InstrumentedQueuedThreadPool.scala:86)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool.runJob(QueuedThreadPool.java:883)",
        "\tat org.eclipse.jetty.util.thread.QueuedThreadPool$Runner.run(QueuedThreadPool.java:1034)",
        "\tat java.lang.Thread.run(Thread.java:750)"
       ],
       "type": "baseError"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "\n",
    "# Load spaCy model for named entity recognition\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load Hugging Face image classification pipeline\n",
    "image_pipeline = pipeline(\"image-classification\")\n",
    "\n",
    "def classify_sentiment(prompt):\n",
    "    \"\"\"Classify sentiment as Positive or Negative.\"\"\"\n",
    "    analysis = TextBlob(prompt)\n",
    "    sentiment = \"Positive\" if analysis.sentiment.polarity > 0 else \"Negative\"\n",
    "    return sentiment\n",
    "\n",
    "def extract_named_entities(prompt):\n",
    "    \"\"\"Extract named entities from the prompt.\"\"\"\n",
    "    doc = nlp(prompt)\n",
    "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "def identify_request_type(prompt):\n",
    "    \"\"\"Identify if the request is for text, image, or translation.\"\"\"\n",
    "    prompt_lower = prompt.lower()\n",
    "    if \"image\" in prompt_lower or \"picture\" in prompt_lower:\n",
    "        return \"image\"\n",
    "    elif prompt_lower.startswith(\"translate to\"):\n",
    "        return \"translation\"\n",
    "    else:\n",
    "        return \"text\"\n",
    "\n",
    "def generate_image_and_captions(prompt):\n",
    "    \"\"\"Generate an image and captions based on the input prompt.\"\"\"\n",
    "    try:\n",
    "        # Generate image using Hugging Face image-classification pipeline\n",
    "        outputs = image_pipeline(prompt, num_images=1)\n",
    "        image_url = outputs[0]['img'] if 'img' in outputs[0] else None\n",
    "\n",
    "        # Generate captions for the image\n",
    "        captions = [\n",
    "            f\"Generated image based on the prompt: {prompt}\",\n",
    "            \"This image was created using AI based on your request.\",\n",
    "            \"An artistic interpretation of the described scene.\"\n",
    "        ]\n",
    "\n",
    "        return image_url, captions\n",
    "    except Exception as e:\n",
    "        return None, [f\"Error generating image: {e}\"]\n",
    "\n",
    "def translate_to_language(text, target_language):\n",
    "    \"\"\"Translate text to specified language (French, Spanish, or German).\"\"\"\n",
    "    if not text:\n",
    "        return None\n",
    "    model_name = f\"Helsinki-NLP/opus-mt-en-{target_language}\"\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "\n",
    "    # Tokenize input text\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    translated = model.generate(**inputs)\n",
    "    translated_text = tokenizer.decode(translated[0], skip_special_tokens=True)\n",
    "    return translated_text\n",
    "\n",
    "def chatbot():\n",
    "    \"\"\"Chatbot loop that processes input and performs tasks.\"\"\"\n",
    "    print(\"Chatbot is running. Type 'exit' to quit.\")\n",
    "    while True:\n",
    "        user_input = input(\"You: \")\n",
    "        if user_input.lower() == 'done':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        # Identify request type\n",
    "        request_type = identify_request_type(user_input)\n",
    "\n",
    "        if request_type == \"image\":\n",
    "            # Generate image and captions\n",
    "            image_url, captions = generate_image_and_captions(user_input)\n",
    "            if image_url:\n",
    "                print(f\"Image URL: {image_url}\")\n",
    "                print(\"Captions:\")\n",
    "                for caption in captions:\n",
    "                    print(f\"  - {caption}\")\n",
    "            else:\n",
    "                print(\"Failed to generate image.\")\n",
    "\n",
    "        elif request_type == \"translation\":\n",
    "            # Extract text and target language\n",
    "            lang_map = {\n",
    "                \"french\": \"fr\",\n",
    "                \"spanish\": \"es\",\n",
    "                \"german\": \"de\"\n",
    "            }\n",
    "            tokens = user_input.split(\"\\\"\")\n",
    "            if len(tokens) >= 2:\n",
    "                target_language = tokens[0].split(\"to\")[1].strip().lower()\n",
    "                text_to_translate = tokens[1].strip()\n",
    "                if target_language in lang_map:\n",
    "                    # Translate to specified language\n",
    "                    translation = translate_to_language(text_to_translate, lang_map[target_language])\n",
    "                    print(f\"Translation to {target_language.capitalize()}: {translation}\")\n",
    "                else:\n",
    "                    print(\"Unsupported language. Supported languages: French, Spanish, German.\")\n",
    "        \n",
    "        else:\n",
    "            # Classify sentiment\n",
    "            sentiment = classify_sentiment(user_input)\n",
    "            print(f\"Sentiment: {sentiment}\")\n",
    "\n",
    "            # Extract named entities\n",
    "            entities = extract_named_entities(user_input)\n",
    "            if entities:\n",
    "                print(\"Named Entities:\")\n",
    "                for entity, label in entities:\n",
    "                    print(f\"  - {entity} ({label})\")\n",
    "            else:\n",
    "                print(\"No named entities found.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    chatbot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae9dadaf-37cd-4ab2-8aa5-1cadc31f3ace",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#image retrival through text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d689a128-ad66-44dc-a244-e0f620f27633",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dd687ec-3d59-45cd-93d2-386265bb8d82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "552290f5-414d-47df-a896-9a0984e03ea1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "chatbot",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}